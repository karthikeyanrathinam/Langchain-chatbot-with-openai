{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "langchain\n",
        "unstructured\n",
        "pandas\n",
        "chromadb\n",
        "tiktoken\n",
        "openai"
      ],
      "metadata": {
        "id": "zoGEbkU_8Gkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxtegzm_7-M0"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt -q\n",
        "!sudo apt-get install tesseract-ocr\n",
        "!sudo apt-get install poppler-utils\n",
        "!pip install pdf2image pytesseract\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
        "!pip install -qU pinecone-client\n",
        "!pip install adaptive\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import pinecone\n",
        "\n",
        "OPENAI_API_KEY = '---'\n",
        "PINECONE_API_KEY = '---'\n",
        "PINECONE_API_ENV = '---'\n",
        "index_name = \"---\"\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_API_ENV\n",
        ")\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def load_pdf_document(file_path):\n",
        "    loader = UnstructuredPDFLoader(file_path)\n",
        "    return loader.load()\n",
        "\n",
        "def split_document_to_chunks(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "def documentsearch(texts, embeddings, index_name):\n",
        "    return Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)\n",
        "\n",
        "def responces(query, docsearch):\n",
        "    docs = docsearch.similarity_search(query, include_metadata=True)\n",
        "    return chain.run(input_documents=docs, question=query)\n",
        "\n",
        "docsearch = None\n",
        "history = []\n",
        "\n",
        "def chatbot(file, question):\n",
        "    global history\n",
        "    global docsearch\n",
        "    if file is not None:\n",
        "        data = load_pdf_document(file.name)\n",
        "        texts = split_document_to_chunks(data)\n",
        "        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "        docsearch = documentsearch(texts, embeddings, index_name)\n",
        "    if docsearch is not None and question is not None:\n",
        "        history.append((\"User\", question))\n",
        "        response = responces(question, docsearch)\n",
        "        history.append((\"Bot\", response))\n",
        "    return history\n",
        "\n",
        "iface = gr.Interface(fn=chatbot, inputs=[\"file\", \"text\"], outputs=\"list\")\n",
        "\n",
        "def clear_chat():\n",
        "    global history\n",
        "    history = []\n",
        "    iface.update_chat([])\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "_c-nx8Lo7_Mf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}